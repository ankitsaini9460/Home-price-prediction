# -*- coding: utf-8 -*-
"""House Price prediction.1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OZp1cGV0j91xigq2GNfZJjdvLpt8mM6d
"""

# import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder

# Load dataset
import zipfile

# Example for CSV file
with zipfile.ZipFile('/content/house.zip', 'r') as zip_ref:
    zip_ref.extract('data.csv', '/content/')

dataset = pd.read_csv('/content/data.csv')

# For Excel file
# dataset = pd.read_excel('house_price_data.xlsx')

print(dataset.head())
print(dataset.shape)

# Check for missing values
print(dataset.isnull().sum())

# Fill missing SalePrice values with mean (if any)
dataset['price'] = dataset['price'].fillna(dataset['price'].mean())

# Drop irrelevant columns like 'Id'
# dataset.drop(['Id'], axis=1, inplace=True) # Removed: 'Id' column does not exist

# Convert 'date' column to datetime objects and extract features
if 'date' in dataset.columns:
    dataset['date'] = pd.to_datetime(dataset['date'])
    dataset['year'] = dataset['date'].dt.year
    dataset['month'] = dataset['date'].dt.month
    dataset['day'] = dataset['date'].dt.day
    dataset = dataset.drop('date', axis=1)


# Separate categorical columns
categorical_cols = dataset.select_dtypes(include=['object']).columns

# OneHotEncode categorical features and convert to dense array
encoder = OneHotEncoder(handle_unknown='ignore')
encoded_features = encoder.fit_transform(dataset[categorical_cols]).toarray()

# Create a DataFrame from the dense array with appropriate column names
encoded_feature_names = encoder.get_feature_names_out(categorical_cols)
encoded_features_df = pd.DataFrame(encoded_features, columns=encoded_feature_names, index=dataset.index)

# Drop original categorical columns and concatenate encoded features
dataset = dataset.drop(categorical_cols, axis=1)
dataset = pd.concat([dataset, encoded_features_df], axis=1)

#Split Dataset into Training and Testing Sets

X = dataset.drop('price', axis=1)
y = dataset['price']

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)

#Train Linear Regression Model
X_train.columns = X_train.columns.astype(str)
X_test.columns = X_test.columns.astype(str)

model = LinearRegression()
model.fit(X_train, y_train)

#Evaluate Model Performance
y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error: {mae:.2f}")
print(f"Mean Squared Error: {mse:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"R^2 Score: {r2:.2f}")

#Visualize Results
plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')
plt.title('Actual vs Predicted House Prices')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.show()